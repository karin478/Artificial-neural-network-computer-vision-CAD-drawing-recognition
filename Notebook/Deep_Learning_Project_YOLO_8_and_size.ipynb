{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81vOehX8NveD",
        "outputId": "30523144-33c1-4cac-d8bf-18932ebb08a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16517, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 16517 (delta 45), reused 50 (delta 16), pack-reused 16402\u001b[K\n",
            "Receiving objects: 100% (16517/16517), 15.17 MiB | 15.63 MiB/s, done.\n",
            "Resolving deltas: 100% (11302/11302), done.\n",
            "/content/yolov5\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.2)\n",
            "Collecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.1.26-py3-none-any.whl (720 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.0/721.0 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (0.42.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, thop, gitpython, ultralytics\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.1.26\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import io\n",
        "from skimage.color import rgba2rgb, gray2rgb\n",
        "from skimage import img_as_ubyte\n",
        "from albumentations import Compose, HueSaturationValue, RandomBrightnessContrast\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your paths\n",
        "zip_path = '/content/drive/MyDrive/Machine Learning Project/training.zip'\n",
        "dataset_dir = '/content/Dataset'\n",
        "\n",
        "# Create destination directory if it does not exist and unzip the file\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_dir)\n",
        "\n",
        "# Define dataset directories\n",
        "images_dir = os.path.join(dataset_dir, 'images')\n",
        "labels_dir = os.path.join(dataset_dir, 'labels')\n",
        "\n",
        "# Function to rotate the images\n",
        "def rotate_bound(image, angle):\n",
        "    (h, w) = image.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
        "    cos = abs(M[0, 0])\n",
        "    sin = abs(M[0, 1])\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        "    return cv2.warpAffine(image, M, (nW, nH))\n",
        "\n",
        "# Function to rotate the labels\n",
        "def rotate_label(label, img_shape, angle):\n",
        "    h, w = img_shape\n",
        "    new_label = []\n",
        "    for line in label:\n",
        "        parts = line.split()\n",
        "        class_id, x_center, y_center, width, height = parts[0], float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
        "        x_center, y_center, width, height = x_center * w, y_center * h, width * w, height * h\n",
        "        if angle == 90:\n",
        "            x_center, y_center = y_center, w - x_center\n",
        "        elif angle == 180:\n",
        "            x_center, y_center = w - x_center, h - y_center\n",
        "        elif angle == 270:\n",
        "            x_center, y_center = h - y_center, x_center\n",
        "        if angle in [90, 270]:\n",
        "            width, height = height, width\n",
        "        new_label.append(f\"{class_id} {x_center / w if angle in [180, 0] else x_center / h} {y_center / h if angle in [180, 0] else y_center / w} {width / w if angle in [180, 0] else width / h} {height / h if angle in [180, 0] else height / w}\")\n",
        "    return new_label\n",
        "\n",
        "# Function to augment and normalize images\n",
        "def augment_and_normalize_image(image):\n",
        "    if image.ndim == 2:  # Grayscale\n",
        "        image = gray2rgb(image)\n",
        "    elif image.ndim == 3 and image.shape[2] == 4:  # RGBA to RGB\n",
        "        image = rgba2rgb(image)\n",
        "    image = img_as_ubyte(image)\n",
        "    transform = Compose([\n",
        "        HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "        RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5)\n",
        "    ])\n",
        "    augmented = transform(image=image)\n",
        "    return augmented['image']\n",
        "\n",
        "# Function to process, rotate and move images and labels\n",
        "def process_and_rotate_images(files, source_images_dir, source_labels_dir, dest_images_dir, dest_labels_dir, augment=False):\n",
        "    for img_name in files:\n",
        "        if img_name.endswith('.png'):\n",
        "            base_name = img_name[:-4]\n",
        "            img_path = os.path.join(source_images_dir, img_name)\n",
        "            label_path = os.path.join(source_labels_dir, base_name + '.txt')\n",
        "            image = cv2.imread(img_path)\n",
        "            with open(label_path, 'r') as file:\n",
        "                original_label = file.readlines()\n",
        "\n",
        "            # Augment and save the original image and label in destination directory if specified\n",
        "            if augment:\n",
        "                image = augment_and_normalize_image(image)\n",
        "            new_img_path = os.path.join(dest_images_dir, img_name)\n",
        "            new_label_path = os.path.join(dest_labels_dir, base_name + '.txt')\n",
        "            cv2.imwrite(new_img_path, image)\n",
        "            with open(new_label_path, 'w') as file:\n",
        "                for line in original_label:\n",
        "                    file.write(f\"{line}\\n\")\n",
        "\n",
        "            # Process for each angle\n",
        "            for angle in [90, 180, 270]:\n",
        "                rotated_img = rotate_bound(image, angle)\n",
        "                rotated_label = rotate_label(original_label, image.shape[:2], angle)\n",
        "                new_img_path = os.path.join(dest_images_dir, f\"{base_name}_{angle}.png\")\n",
        "                new_label_path = os.path.join(dest_labels_dir, f\"{base_name}_{angle}.txt\")\n",
        "                cv2.imwrite(new_img_path, rotated_img)\n",
        "                with open(new_label_path, 'w') as file:\n",
        "                    for line in rotated_label:\n",
        "                        file.write(f\"{line}\\n\")\n",
        "\n",
        "# Get a list of all original image files\n",
        "original_images = [img for img in os.listdir(images_dir) if img.endswith('.png')]\n",
        "\n",
        "# Split the original dataset into training and validation sets\n",
        "train_images, val_images = train_test_split(original_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define new training and validation directories\n",
        "train_dir_images = os.path.join(dataset_dir, 'train_images')\n",
        "train_dir_labels = os.path.join(dataset_dir, 'train_labels')\n",
        "val_dir_images = os.path.join(dataset_dir, 'val_images')\n",
        "val_dir_labels = os.path.join(dataset_dir, 'val_labels')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(train_dir_images, exist_ok=True)\n",
        "os.makedirs(train_dir_labels, exist_ok=True)\n",
        "os.makedirs(val_dir_images, exist_ok=True)\n",
        "os.makedirs(val_dir_labels, exist_ok=True)\n",
        "\n",
        "# Process, rotate, and move the training and validation images and labels\n",
        "process_and_rotate_images(train_images, images_dir, labels_dir, train_dir_images, train_dir_labels, augment=True)\n",
        "process_and_rotate_images(val_images, images_dir, labels_dir, val_dir_images, val_dir_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCMx310fN1ny",
        "outputId": "d6cfc0a9-33eb-4c62-add8-fe3ae1860e2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Your original dataset directory\n",
        "dataset_dir = '/content/Dataset'\n",
        "\n",
        "# New directory structure\n",
        "new_dirs = {\n",
        "    'train_images': 'train/images',\n",
        "    'train_labels': 'train/labels',  # Note: Consider correcting 'lables' to 'labels' if it's a typo in your directory names.\n",
        "    'val_images': 'val/images',\n",
        "    'val_labels': 'val/labels'  # Same here for 'lables'.\n",
        "}\n",
        "\n",
        "# Create new folder structure and move files\n",
        "for old_dir, new_dir in new_dirs.items():\n",
        "    # Create new folders\n",
        "    new_dir_path = os.path.join(dataset_dir, new_dir)\n",
        "    if not os.path.exists(new_dir_path):\n",
        "        os.makedirs(new_dir_path)\n",
        "\n",
        "    # Move files\n",
        "    old_dir_path = os.path.join(dataset_dir, old_dir)\n",
        "    for filename in os.listdir(old_dir_path):\n",
        "        src_file = os.path.join(old_dir_path, filename)\n",
        "        shutil.move(src_file, new_dir_path)\n",
        "\n",
        "# Remove old folders\n",
        "for old_dir in new_dirs.keys():\n",
        "    old_dir_path = os.path.join(dataset_dir, old_dir)\n",
        "    shutil.rmtree(old_dir_path)\n"
      ],
      "metadata": {
        "id": "roHz6tg5N5_B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --epochs 30 --data /content/Dataset/dataset.yaml --weights yolov5x.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5nlMOp1OQ4F",
        "outputId": "b1df5b5f-a827-4caa-a0d6-548d2ec2b10e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-11 02:10:04.960923: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-11 02:10:04.960969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-11 02:10:04.962553: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=/content/Dataset/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-294-gdb125a20 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 108MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:00<00:00, 375MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     53832  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86231272 parameters, 86231272 gradients, 204.7 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/train/labels... 8576 images, 0 backgrounds, 0 corrupt: 100% 8576/8576 [00:02<00:00, 2961.05it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/val/labels... 2148 images, 0 backgrounds, 0 corrupt: 100% 2148/2148 [00:01<00:00, 1080.00it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/val/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.29 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      13.5G    0.06463     0.2084    0.02073        614        640: 100% 536/536 [03:56<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:31<00:00,  2.17it/s]\n",
            "                   all       2148      59644      0.779      0.772      0.817      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      21.2G    0.04647     0.1873    0.01097        809        640: 100% 536/536 [03:39<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.43it/s]\n",
            "                   all       2148      59644      0.823      0.817       0.85      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      21.2G    0.04066     0.1814   0.009653        947        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.45it/s]\n",
            "                   all       2148      59644      0.866      0.837      0.888       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      21.2G    0.03625     0.1782   0.009126        640        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:29<00:00,  2.30it/s]\n",
            "                   all       2148      59644      0.871      0.837      0.899      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      21.2G    0.03385     0.1738   0.008365        836        640: 100% 536/536 [03:39<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.36it/s]\n",
            "                   all       2148      59644      0.865      0.836      0.896      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      21.2G     0.0326      0.171   0.007854        676        640: 100% 536/536 [03:37<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:29<00:00,  2.34it/s]\n",
            "                   all       2148      59644      0.876      0.828      0.898      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      21.2G      0.031     0.1692   0.007499        850        640: 100% 536/536 [03:38<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.39it/s]\n",
            "                   all       2148      59644      0.875      0.826      0.897       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      21.2G     0.0304     0.1642    0.00723        692        640: 100% 536/536 [03:39<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.45it/s]\n",
            "                   all       2148      59644       0.87      0.832      0.899      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      21.2G    0.02969     0.1624   0.006902        792        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.42it/s]\n",
            "                   all       2148      59644      0.863      0.828      0.895      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      21.2G     0.0288     0.1588   0.006706        559        640: 100% 536/536 [03:34<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:29<00:00,  2.34it/s]\n",
            "                   all       2148      59644      0.861      0.826      0.891      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      21.2G    0.02832      0.157   0.006496        581        640: 100% 536/536 [03:39<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.52it/s]\n",
            "                   all       2148      59644      0.872      0.847      0.902      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      21.2G    0.02772     0.1531   0.006245        765        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.37it/s]\n",
            "                   all       2148      59644      0.877      0.831      0.896       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      21.2G    0.02725     0.1525   0.006021        709        640: 100% 536/536 [03:37<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.41it/s]\n",
            "                   all       2148      59644      0.869      0.832       0.89      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      21.2G    0.02674     0.1484   0.005863        867        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.41it/s]\n",
            "                   all       2148      59644      0.873      0.837      0.892      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      21.2G    0.02636     0.1467   0.005718        714        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.40it/s]\n",
            "                   all       2148      59644      0.876      0.839      0.891      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      21.2G    0.02607     0.1435   0.005577        789        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.41it/s]\n",
            "                   all       2148      59644      0.873      0.838      0.888      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      21.2G    0.02566      0.142   0.005455        724        640: 100% 536/536 [03:37<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.45it/s]\n",
            "                   all       2148      59644      0.877      0.817      0.875      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      21.2G    0.02527     0.1389   0.005254        827        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.49it/s]\n",
            "                   all       2148      59644      0.872      0.829      0.875      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      21.2G    0.02492      0.137   0.005109        695        640: 100% 536/536 [03:35<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.43it/s]\n",
            "                   all       2148      59644      0.874       0.83      0.886      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      21.2G    0.02457      0.134   0.005042        802        640: 100% 536/536 [03:36<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.37it/s]\n",
            "                   all       2148      59644      0.872      0.833      0.881       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      21.2G     0.0243     0.1333   0.004937        800        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.51it/s]\n",
            "                   all       2148      59644      0.888       0.83      0.886      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      21.2G    0.02398     0.1306    0.00478        714        640: 100% 536/536 [03:36<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.51it/s]\n",
            "                   all       2148      59644      0.883      0.827      0.881      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      21.2G     0.0237     0.1275   0.004634        682        640: 100% 536/536 [03:36<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.45it/s]\n",
            "                   all       2148      59644      0.882       0.83      0.879      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      21.2G    0.02345     0.1274   0.004509        985        640: 100% 536/536 [03:35<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:28<00:00,  2.42it/s]\n",
            "                   all       2148      59644      0.877      0.836      0.881      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      21.2G    0.02323     0.1253    0.00437        775        640: 100% 536/536 [03:39<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.50it/s]\n",
            "                   all       2148      59644      0.884      0.831      0.881      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      21.2G    0.02307     0.1233   0.004275        638        640: 100% 536/536 [03:37<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.46it/s]\n",
            "                   all       2148      59644       0.88      0.826      0.878      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      21.2G    0.02279     0.1226   0.004201       1134        640: 100% 536/536 [03:38<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.45it/s]\n",
            "                   all       2148      59644      0.882      0.826      0.877      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      21.2G    0.02249     0.1206   0.004035        755        640: 100% 536/536 [03:41<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.48it/s]\n",
            "                   all       2148      59644      0.884       0.83      0.877      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      21.2G    0.02239     0.1195   0.004005        984        640: 100% 536/536 [03:40<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.51it/s]\n",
            "                   all       2148      59644      0.882       0.83      0.876      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      21.2G    0.02221     0.1187   0.003927        841        640: 100% 536/536 [03:38<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:27<00:00,  2.51it/s]\n",
            "                   all       2148      59644      0.877       0.83      0.873      0.616\n",
            "\n",
            "30 epochs completed in 2.080 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 173.0MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 173.0MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86186872 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 68/68 [00:55<00:00,  1.24it/s]\n",
            "                   all       2148      59644      0.873      0.847      0.902      0.626\n",
            "                  room       2148      22300      0.926      0.896      0.947      0.663\n",
            "                window       2148      14780      0.839       0.82      0.871      0.498\n",
            "                  door       2148      22564      0.854      0.825      0.886      0.718\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install opencv-python-headless\n",
        "# YOLO v8 training\n",
        "!yolo train model=yolov8x.pt data=/content/Dataset/dataset.yaml epochs=30 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZX1zvcQVl9J",
        "outputId": "977283ca-e350-4188-ca50-1ffdaf86cbbc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.26 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 39.0/201.2 GB disk)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt to 'yolov8x.pt'...\n",
            "100% 131M/131M [00:00<00:00, 355MB/s]\n",
            "Ultralytics YOLOv8.1.26 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/content/Dataset/dataset.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "2024-03-11 04:17:01.763005: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-11 04:17:01.763061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-11 04:17:01.764715: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8720857  ultralytics.nn.modules.head.Detect           [3, [320, 640, 640]]          \n",
            "Model summary: 365 layers, 68155497 parameters, 68155481 gradients, 258.1 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 269MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/train/labels... 8576 images, 0 backgrounds, 0 corrupt: 100% 8576/8576 [00:50<00:00, 171.29it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/val/labels... 2148 images, 0 backgrounds, 0 corrupt: 100% 2148/2148 [00:15<00:00, 142.07it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/val/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30      13.8G      1.098     0.9366      1.095        680        640: 100% 536/536 [02:22<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:20<00:00,  3.39it/s]\n",
            "                   all       2148      59644      0.837      0.808      0.858      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      14.3G      1.051     0.7805      1.075        806        640: 100% 536/536 [02:02<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.02it/s]\n",
            "                   all       2148      59644      0.843      0.796      0.858      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      14.3G      1.032     0.7575      1.066        672        640: 100% 536/536 [02:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:17<00:00,  3.82it/s]\n",
            "                   all       2148      59644      0.852      0.811      0.877      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30      13.6G      1.008     0.7306      1.055        661        640: 100% 536/536 [02:00<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.02it/s]\n",
            "                   all       2148      59644      0.858      0.825      0.886      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      13.1G     0.9895     0.7086      1.048        864        640: 100% 536/536 [02:00<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.01it/s]\n",
            "                   all       2148      59644      0.863      0.826       0.89      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30      13.9G     0.9813      0.688      1.041        725        640: 100% 536/536 [01:59<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:17<00:00,  3.99it/s]\n",
            "                   all       2148      59644       0.85      0.832      0.888      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30        14G     0.9724     0.6774      1.035        693        640: 100% 536/536 [01:58<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.07it/s]\n",
            "                   all       2148      59644      0.823      0.798      0.871      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30      13.3G     0.9647     0.6695       1.03        685        640: 100% 536/536 [01:58<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.03it/s]\n",
            "                   all       2148      59644      0.857      0.832      0.894      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      13.9G     0.9611     0.6587      1.035        673        640: 100% 536/536 [01:58<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:17<00:00,  3.93it/s]\n",
            "                   all       2148      59644       0.85      0.827      0.889      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      13.5G     0.9475     0.6485      1.027        664        640: 100% 536/536 [01:59<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.06it/s]\n",
            "                   all       2148      59644      0.853      0.835      0.897      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      13.5G     0.9474     0.6418      1.026        865        640: 100% 536/536 [01:58<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:17<00:00,  3.98it/s]\n",
            "                   all       2148      59644      0.855       0.83      0.893       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      14.4G     0.9425     0.6299      1.025        802        640: 100% 536/536 [01:58<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.01it/s]\n",
            "                   all       2148      59644      0.833      0.815      0.873      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      13.6G     0.9375     0.6283      1.021        834        640: 100% 536/536 [01:59<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.08it/s]\n",
            "                   all       2148      59644      0.868      0.842      0.902       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      13.7G       0.93     0.6204       1.02        711        640: 100% 536/536 [01:59<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.09it/s]\n",
            "                   all       2148      59644      0.859      0.835      0.897      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      13.5G     0.9253     0.6111      1.015        629        640: 100% 536/536 [01:58<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.04it/s]\n",
            "                   all       2148      59644      0.848      0.835      0.894      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      13.9G     0.9197     0.6013      1.013        680        640: 100% 536/536 [01:59<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.03it/s]\n",
            "                   all       2148      59644      0.864      0.833      0.895      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30      14.3G     0.9138     0.5944      1.014        903        640: 100% 536/536 [01:58<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.12it/s]\n",
            "                   all       2148      59644      0.853      0.834      0.892      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      13.5G       0.91     0.5893      1.009        813        640: 100% 536/536 [01:59<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.10it/s]\n",
            "                   all       2148      59644      0.857      0.842      0.899      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      13.9G      0.904     0.5829      1.008        755        640: 100% 536/536 [01:58<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.19it/s]\n",
            "                   all       2148      59644      0.861      0.837      0.898      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      13.9G      0.903     0.5759      1.007        828        640: 100% 536/536 [01:58<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.17it/s]\n",
            "                   all       2148      59644      0.869      0.838      0.901      0.626\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30        13G     0.9153     0.5646      1.021        438        640: 100% 536/536 [02:05<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.08it/s]\n",
            "                   all       2148      59644      0.868      0.844      0.903      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30        13G      0.903     0.5489      1.018        408        640: 100% 536/536 [01:57<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.17it/s]\n",
            "                   all       2148      59644       0.83      0.824      0.871        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30        13G     0.8966     0.5409      1.017        412        640: 100% 536/536 [01:57<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.21it/s]\n",
            "                   all       2148      59644      0.867      0.837        0.9      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      13.1G     0.8882     0.5265      1.012        408        640: 100% 536/536 [01:57<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.21it/s]\n",
            "                   all       2148      59644       0.87      0.843      0.905      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30        13G      0.881     0.5161      1.002        448        640: 100% 536/536 [01:57<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.15it/s]\n",
            "                   all       2148      59644      0.852      0.832      0.886      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      13.1G     0.8711     0.5054     0.9996        425        640: 100% 536/536 [01:57<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.20it/s]\n",
            "                   all       2148      59644      0.865       0.84      0.899      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30        13G     0.8642      0.493     0.9999        481        640: 100% 536/536 [01:57<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.12it/s]\n",
            "                   all       2148      59644      0.856      0.835      0.892      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      13.2G     0.8568     0.4821     0.9954        418        640: 100% 536/536 [01:57<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.17it/s]\n",
            "                   all       2148      59644      0.868      0.843      0.901      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      13.2G     0.8444     0.4682     0.9914        412        640: 100% 536/536 [01:57<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.22it/s]\n",
            "                   all       2148      59644      0.858      0.836      0.892      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      13.2G     0.8359     0.4573     0.9841        349        640: 100% 536/536 [01:57<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:16<00:00,  4.19it/s]\n",
            "                   all       2148      59644      0.863      0.841      0.896      0.632\n",
            "\n",
            "30 epochs completed in 1.164 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.26 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "Model summary (fused): 268 layers, 68126457 parameters, 0 gradients, 257.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 68/68 [00:42<00:00,  1.61it/s]\n",
            "                   all       2148      59644       0.87      0.844      0.905      0.638\n",
            "                  room       2148      22300      0.924       0.89      0.946      0.666\n",
            "                window       2148      14780       0.85      0.804      0.876       0.51\n",
            "                  door       2148      22564      0.835      0.837      0.894      0.739\n",
            "Speed: 0.1ms preprocess, 2.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Comparison among YOLOv5, YOLOv5 Small, and YOLOv8\n",
        "\n",
        "This table summarizes the performance metrics for the largest models of YOLOv5, YOLOv5 Small, and YOLOv8 across different categories:\n",
        "\n",
        "| Metric               | YOLOv5 Large  | YOLOv5 Small  | YOLOv8        |\n",
        "| -------------------- | ------------- | ------------- | ------------- |\n",
        "| Number of Layers     | 322           | 157           | 268           |\n",
        "| Number of Parameters | 86,186,872    | 7,018,216     | 68,126,457    |\n",
        "| GFLOPs               | 203.8         | 15.8          | 257.4         |\n",
        "| Overall Precision (P)| 0.873         | 0.88          | 0.87          |\n",
        "| Overall Recall (R)   | 0.847         | 0.84          | 0.844         |\n",
        "| Overall mAP50        | 0.902         | 0.905         | 0.905         |\n",
        "| Overall mAP50-95     | 0.626         | 0.628         | 0.638         |\n",
        "| Room Precision (P)   | 0.926         | 0.918         | 0.924         |\n",
        "| Room Recall (R)      | 0.896         | 0.895         | 0.89          |\n",
        "| Room mAP50           | 0.947         | 0.946         | 0.946         |\n",
        "| Room mAP50-95        | 0.663         | 0.661         | 0.666         |\n",
        "| Window Precision (P) | 0.839         | 0.853         | 0.85          |\n",
        "| Window Recall (R)    | 0.82          | 0.816         | 0.804         |\n",
        "| Window mAP50         | 0.871         | 0.879         | 0.876         |\n",
        "| Window mAP50-95      | 0.498         | 0.501         | 0.51          |\n",
        "| Door Precision (P)   | 0.854         | 0.868         | 0.835         |\n",
        "| Door Recall (R)      | 0.825         | 0.81          | 0.837         |\n",
        "| Door mAP50           | 0.886         | 0.89          | 0.894         |\n",
        "| Door mAP50-95        | 0.718         | 0.723         | 0.739         |\n",
        "\n",
        "From the updated comparison table, we can observe the following:\n",
        "\n",
        "1. **Model Complexity and Computational Cost**: The small version of YOLOv5 offers a significant reduction in both the number of layers and parameters compared to its larger counterpart and YOLOv8. It also requires substantially less computational power (15.8 GFLOPs).\n",
        "\n",
        "2. **Performance (Precision, Recall, mAP)**:\n",
        "   - The small version of YOLOv5 shows competitive performance compared to the larger models, particularly in overall precision and mAP50.\n",
        "   - Despite its smaller size, YOLOv5 Small performs comparably to or slightly better than YOLOv5 Large in several metrics and is competitive with YOLOv8, especially considering its lower computational requirements.\n",
        "\n",
        "This data suggests that YOLOv5 Small could be a highly efficient model for environments with stringent computational or storage limitations while still maintaining high levels of accuracy.\n"
      ],
      "metadata": {
        "id": "UztsVOznDRp_"
      }
    }
  ]
}
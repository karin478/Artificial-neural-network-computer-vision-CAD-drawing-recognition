{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpt6bEdQXLwQ",
        "outputId": "b2415da1-c341-4218-c183-341da7118229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16512, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 16512 (delta 41), reused 49 (delta 15), pack-reused 16408\u001b[K\n",
            "Receiving objects: 100% (16512/16512), 15.17 MiB | 29.82 MiB/s, done.\n",
            "Resolving deltas: 100% (11301/11301), done.\n",
            "/content/yolov5\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.2)\n",
            "Collecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.1.24-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m719.5/719.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, thop, gitpython, ultralytics\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.1.24\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'path_to_your_zip_file' with the path to your zip file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/Machine Learning Project/training.zip'\n",
        "\n",
        "# Replace 'destination_folder' with the path where you want to unzip your files\n",
        "destination_folder = '/content/Dataset'\n",
        "\n",
        "# Create destination directory if it does not exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_folder)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths\n",
        "dataset_dir = '/content/Dataset'\n",
        "images_dir = os.path.join(dataset_dir, 'images')\n",
        "labels_dir = os.path.join(dataset_dir, 'labels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQeafdaaXWA6",
        "outputId": "8eacfec8-ee9e-4485-c9d0-5a9fd6a1c568"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import exposure, io\n",
        "import numpy as np\n",
        "from skimage import img_as_ubyte\n",
        "import shutil\n",
        "from albumentations import Compose, HueSaturationValue, RandomBrightnessContrast\n",
        "from skimage.color import rgba2rgb, gray2rgb\n",
        "\n",
        "\n",
        "# Get a list of all image files\n",
        "all_images = os.listdir(images_dir)\n",
        "\n",
        "# Split the dataset into training and validation\n",
        "train_images, val_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "def augment_and_normalize_image(image):\n",
        "    # Check if the image is grayscale or RGBA, and convert to RGB if necessary\n",
        "    if image.ndim == 2:  # Grayscale\n",
        "        image = gray2rgb(image)\n",
        "    elif image.ndim == 3 and image.shape[2] == 4:  # RGBA to RGB\n",
        "        image = rgba2rgb(image)\n",
        "\n",
        "    # Ensure the image is uint8 before applying Albumentations augmentations\n",
        "    image = img_as_ubyte(image)\n",
        "\n",
        "    # Define augmentation pipeline\n",
        "    transform = Compose([\n",
        "        HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "        RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5)\n",
        "    ])\n",
        "\n",
        "    # Apply transformations\n",
        "    augmented = transform(image=image)\n",
        "    image = augmented['image']\n",
        "\n",
        "    return image\n",
        "\n",
        "def process_and_move_files(files, source_folder, dest_folder, augment=False):\n",
        "    for file in files:\n",
        "        # Process image\n",
        "        image_path = os.path.join(source_folder, file)\n",
        "        image = io.imread(image_path)\n",
        "\n",
        "        # Apply augmentations if specified\n",
        "        if augment:\n",
        "            image = augment_and_normalize_image(image)\n",
        "\n",
        "        # Save the processed image\n",
        "        io.imsave(os.path.join(dest_folder, file), image)  # Save image to destination folder\n",
        "\n",
        "        # Move corresponding label file\n",
        "        label_file = file.replace('jpg', 'txt').replace('png', 'txt')\n",
        "        shutil.move(os.path.join(source_folder.replace('images', 'labels'), label_file), dest_folder.replace('images', 'labels'))\n",
        "\n",
        "\n",
        "\n",
        "# Process and move the files\n",
        "train_dir = os.path.join(dataset_dir, 'images/train')\n",
        "val_dir = os.path.join(dataset_dir, 'images/val')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(train_dir.replace('images', 'labels'), exist_ok=True)\n",
        "os.makedirs(val_dir.replace('images', 'labels'), exist_ok=True)\n",
        "\n",
        "process_and_move_files(train_images, images_dir, train_dir, augment=True)  # Apply augmentation to training images\n",
        "process_and_move_files(val_images, images_dir, val_dir)\n"
      ],
      "metadata": {
        "id": "4Un5Y0liXqQx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the only parameter modification test here, changing the original 640 image size to a larger 1280 size. Test whether a larger image resolution can give the model better performance."
      ],
      "metadata": {
        "id": "Shp81HaRz2Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv5 on custom dataset for a certain number of epochs\n",
        "!python train.py --img 1280 --batch 16 --epochs 50 --data /content/Dataset/dataset.yaml --weights yolov5s.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckC29XUfXWtx",
        "outputId": "2a148df8-15bc-47e5-9a7e-615eeb607c8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-07 14:57:41.317078: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 14:57:41.317124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 14:57:41.318500: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/Dataset/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-290-gb2ffe055 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 43.0MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 274MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train... 2144 images, 0 backgrounds, 0 corrupt: 100% 2144/2144 [00:00<00:00, 4722.27it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val... 537 images, 0 backgrounds, 0 corrupt: 100% 537/537 [00:00<00:00, 1862.00it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.08 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49      13.5G    0.08318     0.2876    0.02854        996       1280: 100% 134/134 [01:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.13s/it]\n",
            "                   all        537      14635      0.427      0.502        0.4      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49      11.7G    0.05945     0.2566    0.01462        764       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.00s/it]\n",
            "                   all        537      14635      0.515       0.61      0.565       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49      12.6G    0.05468     0.2474    0.01179        809       1280: 100% 134/134 [01:31<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.14s/it]\n",
            "                   all        537      14635      0.613      0.755      0.685      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49      12.6G    0.04716      0.244   0.009967        696       1280: 100% 134/134 [01:30<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.17s/it]\n",
            "                   all        537      14635      0.813      0.774      0.827      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49      12.6G    0.04156     0.2389   0.009034        757       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.06s/it]\n",
            "                   all        537      14635      0.812      0.806      0.844      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49      12.6G    0.03912     0.2348   0.008591        664       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.04s/it]\n",
            "                   all        537      14635      0.851      0.818      0.865      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49      12.6G    0.03576     0.2321   0.008233        912       1280: 100% 134/134 [01:31<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.12s/it]\n",
            "                   all        537      14635      0.852      0.809      0.864      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49      12.6G    0.03464     0.2263   0.008138        662       1280: 100% 134/134 [01:34<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.04s/it]\n",
            "                   all        537      14635      0.861      0.808      0.871      0.555\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49      12.6G    0.03409      0.224   0.008068        749       1280: 100% 134/134 [01:35<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:15<00:00,  1.08it/s]\n",
            "                   all        537      14635      0.862      0.826      0.881      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49      12.6G    0.03158     0.2268   0.007776        772       1280: 100% 134/134 [01:32<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.12s/it]\n",
            "                   all        537      14635      0.861      0.822      0.879      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49      12.6G    0.03253     0.2227    0.00796        834       1280: 100% 134/134 [01:32<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.04s/it]\n",
            "                   all        537      14635      0.869      0.823      0.885      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49      12.6G    0.03113     0.2162   0.007677        952       1280: 100% 134/134 [01:34<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.02it/s]\n",
            "                   all        537      14635      0.865      0.822      0.882      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49      12.6G    0.02986     0.2193    0.00754        690       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.03s/it]\n",
            "                   all        537      14635      0.862      0.811      0.875      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49      12.6G    0.02998     0.2111   0.007304        760       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.04it/s]\n",
            "                   all        537      14635      0.863      0.828      0.883        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49      12.6G    0.02963     0.2149   0.007414        778       1280: 100% 134/134 [01:30<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.08s/it]\n",
            "                   all        537      14635      0.867      0.818      0.881      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49      12.6G    0.02905     0.2118   0.007414        566       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.03s/it]\n",
            "                   all        537      14635      0.868      0.829      0.889      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49      12.6G    0.02865     0.2115   0.007099        853       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.04it/s]\n",
            "                   all        537      14635      0.866      0.833      0.891      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49      12.6G    0.02833      0.208   0.007075        745       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.12s/it]\n",
            "                   all        537      14635      0.863      0.814      0.882      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49      12.6G    0.02802     0.2085   0.006885        724       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.01it/s]\n",
            "                   all        537      14635      0.865      0.832       0.89      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49      12.6G    0.02754     0.2067   0.006798        807       1280: 100% 134/134 [01:31<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.06s/it]\n",
            "                   all        537      14635      0.867      0.835      0.895      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49      12.6G    0.02757     0.2035   0.006835        565       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.09s/it]\n",
            "                   all        537      14635      0.864      0.825      0.889      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49      12.6G    0.02709     0.2046   0.006669        794       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.03s/it]\n",
            "                   all        537      14635      0.874       0.83      0.894      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49      12.6G    0.02647     0.2039   0.006694        691       1280: 100% 134/134 [01:34<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.09s/it]\n",
            "                   all        537      14635      0.867       0.83      0.892      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49      12.6G    0.02681     0.2064   0.006582        812       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.08s/it]\n",
            "                   all        537      14635      0.862       0.83      0.888      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49      12.6G    0.02647     0.1999   0.006556        829       1280: 100% 134/134 [01:35<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.01it/s]\n",
            "                   all        537      14635      0.863      0.831      0.891      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49      12.6G    0.02623     0.1999   0.006452        825       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.00s/it]\n",
            "                   all        537      14635      0.861       0.83      0.892      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49      12.6G    0.02566     0.1964   0.006365        664       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.11s/it]\n",
            "                   all        537      14635      0.869      0.833      0.893      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49      12.6G    0.02576     0.1986   0.006292        881       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.16s/it]\n",
            "                   all        537      14635      0.866       0.81      0.884      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49      12.6G    0.02545     0.1961    0.00613        685       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.08s/it]\n",
            "                   all        537      14635      0.872      0.822      0.889      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49      12.6G     0.0253       0.19   0.006108        703       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.01it/s]\n",
            "                   all        537      14635      0.864      0.826      0.891      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49      12.6G    0.02488     0.1942   0.006189        814       1280: 100% 134/134 [01:32<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:19<00:00,  1.12s/it]\n",
            "                   all        537      14635      0.849      0.824      0.888      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49      12.6G    0.02475     0.1926    0.00584        707       1280: 100% 134/134 [01:34<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.02it/s]\n",
            "                   all        537      14635      0.864      0.815      0.883      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49      12.6G    0.02488     0.1907   0.005938        642       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.09s/it]\n",
            "                   all        537      14635      0.871      0.834      0.894      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49      12.6G    0.02411      0.186   0.005515        757       1280: 100% 134/134 [01:32<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.02s/it]\n",
            "                   all        537      14635      0.862      0.837      0.893       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49      12.6G    0.02438     0.1899   0.005654        565       1280: 100% 134/134 [01:34<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:15<00:00,  1.06it/s]\n",
            "                   all        537      14635      0.869      0.833      0.893      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49      12.6G    0.02383     0.1854   0.005694        897       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.00it/s]\n",
            "                   all        537      14635      0.868      0.825      0.891      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49      12.6G      0.024     0.1858   0.005606        719       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.07s/it]\n",
            "                   all        537      14635      0.871      0.834      0.892      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49      12.6G    0.02397     0.1847   0.005713        862       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.03s/it]\n",
            "                   all        537      14635       0.87      0.834      0.895      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49      12.6G    0.02384      0.183   0.005429        860       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.05it/s]\n",
            "                   all        537      14635      0.861      0.839      0.894      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49      12.6G    0.02365     0.1808   0.005434        589       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:16<00:00,  1.03it/s]\n",
            "                   all        537      14635      0.877      0.836      0.897      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49      12.6G    0.02341     0.1816   0.005403        696       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.02s/it]\n",
            "                   all        537      14635      0.871      0.841      0.898      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49      12.6G    0.02346     0.1794   0.005479        649       1280: 100% 134/134 [01:32<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.06s/it]\n",
            "                   all        537      14635      0.875      0.836      0.894      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49      12.6G    0.02311     0.1814   0.005199        792       1280: 100% 134/134 [01:32<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.08s/it]\n",
            "                   all        537      14635      0.875      0.836      0.897       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49      12.6G    0.02326     0.1777   0.005441        613       1280: 100% 134/134 [01:32<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.06s/it]\n",
            "                   all        537      14635      0.883      0.834      0.897      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49      12.6G    0.02321     0.1767    0.00527        713       1280: 100% 134/134 [01:31<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.06s/it]\n",
            "                   all        537      14635      0.874      0.832      0.893      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49      12.6G    0.02305     0.1755   0.005317        879       1280: 100% 134/134 [01:33<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.04s/it]\n",
            "                   all        537      14635      0.875      0.838      0.898      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49      12.6G    0.02288     0.1768   0.004919        587       1280: 100% 134/134 [01:33<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:15<00:00,  1.13it/s]\n",
            "                   all        537      14635      0.879      0.835      0.896      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49      12.6G    0.02286     0.1738   0.005194        824       1280: 100% 134/134 [01:32<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.07s/it]\n",
            "                   all        537      14635      0.878      0.833      0.895      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49      12.6G     0.0228     0.1772   0.005098        730       1280: 100% 134/134 [01:32<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:17<00:00,  1.02s/it]\n",
            "                   all        537      14635      0.872      0.835      0.897      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49      12.6G    0.02259      0.174   0.005009        588       1280: 100% 134/134 [01:31<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:18<00:00,  1.09s/it]\n",
            "                   all        537      14635      0.876      0.839      0.897      0.645\n",
            "\n",
            "50 epochs completed in 1.555 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.7MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.7MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  18% 3/17 [00:10<00:47,  3.38s/it]WARNING âš ï¸ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 17/17 [00:31<00:00,  1.85s/it]\n",
            "                   all        537      14635       0.87      0.791      0.852      0.614\n",
            "                  room        537       5404      0.909       0.85      0.896      0.654\n",
            "                window        537       3733      0.858      0.759      0.831      0.511\n",
            "                  door        537       5498      0.842      0.763      0.828      0.677\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance Comparison Report: 640 vs 1280 Image Sizes\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This report provides a comparative analysis between two different image sizes, 640 and 1280, used in training a deep learning object detection model. The objective is to assess the impact of image size on model performance metrics including Precision, Recall, mAP50, and mAP50-95.\n",
        "\n",
        "## Overall Performance Comparison\n",
        "\n",
        "| Metric     | Image Size 640 | Image Size 1280 |\n",
        "|------------|----------------|-----------------|\n",
        "| Precision  | 0.882          | 0.87            |\n",
        "| Recall     | 0.839          | 0.791           |\n",
        "| mAP50      | 0.901          | 0.852           |\n",
        "| mAP50-95   | 0.643          | 0.614           |\n",
        "\n",
        "## Performance by Class\n",
        "\n",
        "### Room\n",
        "\n",
        "| Metric     | Image Size 640 | Image Size 1280 |\n",
        "|------------|----------------|-----------------|\n",
        "| Precision  | 0.909          | 0.909           |\n",
        "| Recall     | 0.892          | 0.85            |\n",
        "| mAP50      | 0.941          | 0.896           |\n",
        "| mAP50-95   | 0.679          | 0.654           |\n",
        "\n",
        "### Window\n",
        "\n",
        "| Metric     | Image Size 640 | Image Size 1280 |\n",
        "|------------|----------------|-----------------|\n",
        "| Precision  | 0.88           | 0.858           |\n",
        "| Recall     | 0.803          | 0.759           |\n",
        "| mAP50      | 0.881          | 0.831           |\n",
        "| mAP50-95   | 0.53           | 0.511           |\n",
        "\n",
        "### Door\n",
        "\n",
        "| Metric     | Image Size 640 | Image Size 1280 |\n",
        "|------------|----------------|-----------------|\n",
        "| Precision  | 0.858          | 0.842           |\n",
        "| Recall     | 0.821          | 0.763           |\n",
        "| mAP50      | 0.881          | 0.828           |\n",
        "| mAP50-95   | 0.72           | 0.677           |\n",
        "\n",
        "## Analysis\n",
        "\n",
        "Upon comparing the two image sizes, it is evident that the model trained with 640 image size generally outperforms the one trained with 1280 image size across all main performance metrics. Specifically:\n",
        "\n",
        "- The **Precision** sees a slight drop from 640 to 1280, indicating a marginal decrease in the proportion of true positive detections.\n",
        "- The **Recall** metric shows a more significant decrease, suggesting that the model with 1280 image size is less capable of identifying all relevant instances in the dataset.\n",
        "- **mAP50** and **mAP50-95** both decrease as the image size increases, which implies that the model's ability to accurately detect and localize objects diminishes with larger image sizes.\n",
        "\n",
        "### Considerations\n",
        "\n",
        "- **Computational Load**: The increased image size leads to higher computational requirements and longer inference times, which might not be justifiable given the decrease in performance metrics.\n",
        "- **Data Representation**: Larger image sizes could introduce more complexity and variability that the current model architecture or training regimen may not handle optimally.\n",
        "- **Optimization and Tuning**: The model might require different tuning or a different architecture to fully leverage the higher resolution provided by the 1280 image size.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The comparative analysis between the 640 and 1280 image sizes demonstrates that, for this specific object detection model, a smaller image size of 640 provides better performance across several key metrics. While larger image sizes can theoretically offer more detailed information for object detection, they also pose greater challenges for model training and may require more computational resources. Future work should focus on optimizing model parameters and architectures to better accommodate larger image sizes or consider the trade-offs between resolution and performance for their specific application requirements.\n"
      ],
      "metadata": {
        "id": "O6IRqyLHzmN2"
      }
    }
  ]
}